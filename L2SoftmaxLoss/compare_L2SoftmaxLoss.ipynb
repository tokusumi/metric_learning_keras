{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 Softmax Loss\n",
    "L2 Softmax Lossを用いてmetiric learningを行う。\n",
    "mninst datasetに対して、Neural Networkで特徴空間にmapし、距離関数で手書き文字の相違を判定させる。\n",
    "通常の分類タスクでよく用いられるSoftmax Lossはmetric learningでも使われるようなので、L2 Softmax Lossと比較することにする。\n",
    "\n",
    "## 特徴\n",
    "- 実装が簡単。よく用いられるsoftmax lossを少し修正するだけでよい。特別なlossは必要ないため非常に手軽に試せる\n",
    "- 似ているもののcosine similarityは大きく、異なるものは小さくなるように学習する\n",
    "\n",
    "## 表式\n",
    "最終層の出力にL2 normalization -> scale変換 -> softmax layerを施し、cross-entropyをloss関数とし、学習する。推論時はL2 normalization以下を省くことで入力画像が特徴空間にmapされる。2つの入力を特徴空間にmapし、cosine similarityを求める。ある閾値を超えた場合、2つの入力が同一であると判定する。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "mnist.load_data()\n",
    "print('success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set const\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(img_rows, img_cols, num_classes):\n",
    "    # the data, split between train and test sets\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "        x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "        input_shape = (1, img_rows, img_cols)\n",
    "    else:\n",
    "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "        input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    return x_train, x_test, y_train, y_test, input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define and fit model with L2 softmax Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape, num_classes, alpha=0.3):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    # l2 softmax\n",
    "    model.add(Dense(128, activation='linear', \n",
    "                                    activity_regularizer=regularizers.l2(alpha)\n",
    "                   ))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Trains a simple convnet on the MNIST dataset.\n",
    "'''\n",
    "\n",
    "x_train, x_test, y_train, y_test, input_shape = make_dataset(img_rows, img_cols, num_classes)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "model = make_model(input_shape, num_classes, alpha=0.01)\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 158s 3ms/step - loss: 1.3550 - acc: 0.9204 - val_loss: 0.7465 - val_acc: 0.9796\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 141s 2ms/step - loss: 0.5963 - acc: 0.9813 - val_loss: 0.4743 - val_acc: 0.9861\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 138s 2ms/step - loss: 0.4211 - acc: 0.9868 - val_loss: 0.3612 - val_acc: 0.9888\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 140s 2ms/step - loss: 0.3436 - acc: 0.9898 - val_loss: 0.3172 - val_acc: 0.9894\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 139s 2ms/step - loss: 0.2975 - acc: 0.9917 - val_loss: 0.2771 - val_acc: 0.9904\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 141s 2ms/step - loss: 0.2665 - acc: 0.9931 - val_loss: 0.2570 - val_acc: 0.9904\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 140s 2ms/step - loss: 0.2438 - acc: 0.9940 - val_loss: 0.2435 - val_acc: 0.9911\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 141s 2ms/step - loss: 0.2261 - acc: 0.9947 - val_loss: 0.2190 - val_acc: 0.9912\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 140s 2ms/step - loss: 0.2125 - acc: 0.9952 - val_loss: 0.2080 - val_acc: 0.9912\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 143s 2ms/step - loss: 0.2011 - acc: 0.9954 - val_loss: 0.2055 - val_acc: 0.9910\n",
      "Test loss: 0.09844313929080963\n",
      "Test accuracy: 0.991\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model_L2softmaxLoss.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"model_L2softmaxLoss.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define and fit base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_basemodel(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='linear'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel = make_basemodel(input_shape, num_classes)\n",
    "\n",
    "basemodel.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 129s 2ms/step - loss: 0.1761 - acc: 0.9469 - val_loss: 0.0649 - val_acc: 0.9802\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 99s 2ms/step - loss: 0.0603 - acc: 0.9816 - val_loss: 0.0540 - val_acc: 0.9816\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 94s 2ms/step - loss: 0.0443 - acc: 0.9869 - val_loss: 0.0461 - val_acc: 0.9850\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 91s 2ms/step - loss: 0.0366 - acc: 0.9889 - val_loss: 0.0350 - val_acc: 0.9881\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 100s 2ms/step - loss: 0.0301 - acc: 0.9904 - val_loss: 0.0321 - val_acc: 0.9891\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 96s 2ms/step - loss: 0.0260 - acc: 0.9916 - val_loss: 0.0377 - val_acc: 0.9882\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 91s 2ms/step - loss: 0.0215 - acc: 0.9934 - val_loss: 0.0340 - val_acc: 0.9888\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 95s 2ms/step - loss: 0.0196 - acc: 0.9934 - val_loss: 0.0311 - val_acc: 0.9910\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 106s 2ms/step - loss: 0.0181 - acc: 0.9943 - val_loss: 0.0306 - val_acc: 0.9908\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 101s 2ms/step - loss: 0.0161 - acc: 0.9949 - val_loss: 0.0323 - val_acc: 0.9913\n",
      "Test loss: 0.03231845000804315\n",
      "Test accuracy: 0.9913\n"
     ]
    }
   ],
   "source": [
    "basemodel.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = basemodel.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel.save_weights(\"basemodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel.load_weights(\"basemodel.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make metric model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance(inputs):\n",
    "    x1, x2 = inputs\n",
    "    x1 = K.l2_normalize(x1, axis=-1)\n",
    "    x2 = K.l2_normalize(x2, axis=-1)\n",
    "    return K.sum(x1 * x2, axis=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_metric_model(base_model):\n",
    "    layer_name = base_model.layers[-2].name\n",
    "    base_model.layers[-2].activity_regularizer = None\n",
    "\n",
    "    x1_input = Input(shape=base_model.input.shape[1:].as_list())\n",
    "    x1 = Model(inputs=base_model.input, outputs=base_model.get_layer(layer_name).output)(x1_input)\n",
    "\n",
    "    x2_input = Input(shape=base_model.input.shape[1:].as_list())\n",
    "    x2 = Model(inputs=base_model.input, outputs=base_model.get_layer(layer_name).output)(x2_input)\n",
    "\n",
    "    distance = Lambda(cosine_distance)([x1, x2])\n",
    "    model = Model(inputs=[x1_input, x2_input], outputs=distance)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make metric model with L2 softmax Loss\n",
    "metric_model= make_metric_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 128)          1198592     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 128)          1198592     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           model_1[1][0]                    \n",
      "                                                                 model_2[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,198,592\n",
      "Trainable params: 1,198,592\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "metric_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make metric model  with base model\n",
    "metric_basemodel= make_metric_model(basemodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_4 (Model)                 (None, 128)          1198592     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_5 (Model)                 (None, 128)          1198592     input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1)            0           model_4[1][0]                    \n",
      "                                                                 model_5[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,198,592\n",
      "Trainable params: 1,198,592\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "metric_basemodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check identity map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = metric_model.predict([x_test[:1], x_test[:1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_with_diff = metric_model.predict([x_test[:1], x_test[1:2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01261933]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_with_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_pred, y_test, th=0.5):\n",
    "    \"\"\"calculation of precission and recall\"\"\"\n",
    "    corr = np.sum((y_pred > th).astype(np.float32) * y_test)\n",
    "    recall = corr / np.sum(y_test)\n",
    "    precision = corr / np.sum((y_pred > th).astype(np.float32))\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(x_test, y_test, metric_model):\n",
    "    # new label: same label=1 or not=0\n",
    "    y_test_match = np.sum(y_test[:-1] * y_test[1:], axis=-1)\n",
    "    \n",
    "    # the number of same label combination\n",
    "    print(\"the number of same label: \", np.sum(y_test_match))\n",
    "\n",
    "    y_pred_match = metric_model.predict([x_test[:-1], x_test[1:]])\n",
    "    y_pred_match = y_pred_match.reshape(-1)\n",
    "\n",
    "    result = [metrics(y_pred_match, y_test_match, th=th) for th in [0.05*f for f in range(20)]]\n",
    "    precision = [f for f, g in result]\n",
    "    recall = [g for f, g in result]\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of same label:  845.0\n"
     ]
    }
   ],
   "source": [
    "# calculation of precision and recall on base model\n",
    "baseprecision, baserecall = calc_metrics(x_test, y_test, metric_basemodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of same label:  845.0\n"
     ]
    }
   ],
   "source": [
    "# calculation of precision and recall on model with L2 softmax Loss\n",
    "precision, recall = calc_metrics(x_test, y_test, metric_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot PR-curve\n",
    "model with L2 softmax Loss suits on metric learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tokusumi/Work/python/tensorflow/env/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "\n",
    "ax.plot(precision,recall, label='l2')\n",
    "ax.plot(baseprecision, baserecall, label='base')\n",
    "\n",
    "ax.set_title('PR curve')\n",
    "ax.set_xlabel('precision')\n",
    "ax.set_ylabel('recall')\n",
    "plt.legend()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.4",
    "jupytext_version": "1.2.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
